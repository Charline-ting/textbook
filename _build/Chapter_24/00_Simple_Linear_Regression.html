---
redirect_from:
  - "/chapter-24/00-simple-linear-regression"
interact_link: content/Chapter_24/00_Simple_Linear_Regression.ipynb
kernel_name: python3
has_widgets: false
title: 'Simple Linear Regression'
prev_page:
  url: /Chapter_23/04_Independence.html
  title: 'Independence'
next_page:
  url: /Chapter_24/01_Bivariate_Normal_Distribution.html
  title: 'Bivariate Normal Distribution'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Simple-Linear-Regression">Simple Linear Regression<a class="anchor-link" href="#Simple-Linear-Regression"> </a></h1>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In data science, regression models are widely used for prediction. This chapter examines linear least squares from a probabilistic perspective. The focus is on <em>simple</em> regression, that is, prediction based on one numerical attribute.</p>
<p>When the joint distribution of the attribute $X$ and the response $Y$ is bivariate normal, the empirical distribution of $(X, Y)$ has the football shape so familiar from Data 8. We will start with a geometric interpretation of correlation, as that is helpful for understanding both regression and the bivariate normal. The equation of the regression line, which we will derive, can be written in several ways; by the end of the chapter we will have written it in the way that is most easily extended to multiple regression.</p>

</div>
</div>
</div>
</div>

 

