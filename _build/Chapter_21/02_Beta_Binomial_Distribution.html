---
redirect_from:
  - "/chapter-21/02-beta-binomial-distribution"
interact_link: content/Chapter_21/02_Beta_Binomial_Distribution.ipynb
kernel_name: python3
kernel_path: content/Chapter_21
has_widgets: false
title: |-
  The Beta-Binomial Distribution
pagenum: 108
prev_page:
  url: /Chapter_21/01_Updating_and_Prediction.html
next_page:
  url: /Chapter_21/03_Long_Run_Proportion_of_Heads.html
suffix: .ipynb
search: p k sn n r s x distribution c frac beta rk binom binomial given heads density e section prior tosses coin probability posterior cdot gamma rs uniform int mid dp previous let constant ways f vert using pk choose uniformly between conditional unconditional align expectation nx proportion big denominator calculation calculations carried under condition never needed event part made integrate writing recalling bayes rule equate constants probabilities range through where discrete called parameters lands picked according pair particularly interesting thats case reduces theres answer conclusion toss times ldots selected value checking integration prefer directly conditioning begin fx end therefore

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">The Beta-Binomial Distribution</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Beta-Binomial-Distribution">The Beta-Binomial Distribution<a class="anchor-link" href="#The-Beta-Binomial-Distribution"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As in the previous section, let $X$ have the beta $(r, s)$ prior, and given $X = p$ let the $S_n$ be the number of heads in the first $n$ tosses of a $p$-coin.</p>
<p>All the calculations we carried out in the previous section were under the condition that $S_n = k$, but we never needed to find the probability of this event. It was part of the constant that made the posterior density of $X$ integrate to 1.</p>
<p>We can now find $P(S_n = k)$ by writing the posterior density in two ways:</p>
<ul>
<li>By recalling that it is the beta $(r+k, s+n-k)$ density:</li>
</ul>
$$
f_{X \vert S_n=k} (p) ~ = ~ C(r+k, s+n-k)p^{r+k-1}(1-p)^{s+n-k-1}, ~~~~ 0 &lt; p &lt; 1
$$<ul>
<li>By using Bayes' Rule:</li>
</ul>
$$
f_{X \vert S_n=k} (p) ~ = ~ \frac{C(r, s) p^{r-1}(1-p)^{s-1} \cdot \binom{n}{k} p^k (1-p)^{n-k}}{P(S_n = k)}, ~~~~ 0 &lt; p &lt; 1
$$<p>Now equate constants:</p>
$$
\frac{C(r, s) \binom{n}{k}}{P(S_n = k)} ~ = ~ C(r+k, s+n-k)
$$
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Beta-Binomial-Probabilities">Beta-Binomial Probabilities<a class="anchor-link" href="#Beta-Binomial-Probabilities"> </a></h3><p>So for $k$ in the range 0 through $n$,</p>
$$
P(S_n = k) ~ = ~  \binom{n}{k} \frac{C(r, s)}{C(r+k, s+n-k)}
$$<p>where $C(r,s)$ is the constant in the beta $(r, s)$ density, given by</p>
$$
C(r, s) ~ = ~ \frac{\Gamma(r+s)}{\Gamma(r)\Gamma(s)}
$$<p>This discrete distribution is called the <em>beta-binomial</em> distribution with parameters $r$, $s$, and $n$. It is the distribution of the number of heads in $n$ tosses of a coin that lands heads with a probability picked according to the beta $(r, s)$ distribution.</p>
<p>One $(r, s)$ pair is particularly interesting: $r = s = 1$. That's the case when $X$ has the uniform prior. The distribution of $S_n$ reduces to</p>
$$
P(S_n = k ) ~ = ~ \frac{n!}{k!(n-k)!} \cdot \frac{1!}{0!0!} \cdot \frac{k!(n-k)!}{(n+1)!} ~ = ~ \frac{1}{n+1}
$$<p>There's no $k$ in the answer! The conclusion is that if you choose $p$ uniformly between 0 and 1 and toss a $p$-coin $n$ times, <em>the distribution of the number of heads is uniform</em> on $\{ 0, 1, 2, \ldots, n\}$.</p>
<p>If you choose $p$ uniformly between 0 and 1, then for the conditional distribution of $S_n$ given that $p$ was the selected value is binomial $(n, p)$. But the unconditional distribution of $S_n$ is uniform.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Checking-by-Integration">Checking by Integration<a class="anchor-link" href="#Checking-by-Integration"> </a></h3><p>If you prefer, you can find the distribution of $S_n$ directly, by conditioning on $X$.
$$
\begin{align*}
P(S_n = k) ~ &amp;= \int_0^1 P(S_n = k \mid X = p)f_X(p)dp \\ \\
&amp;= ~ \int_0^1 \binom{n}{k} p^k(1-p)^{n-k}C(r, s)p^{r-1}(1-p)^{s-1}dp \\ \\
&amp;= ~ \binom{n}{k} C(r, s) \int_0^1 p^{r+k-1}(1-p)^{s+n-k-1} dp \\ \\
&amp;= ~ \binom{n}{k} C(r, s) \frac{1}{C(r+k, s+n-k)}
\end{align*}
$$</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expectation">Expectation<a class="anchor-link" href="#Expectation"> </a></h3><p>Given $X = p$, the conditional distribution of $S_n$ is binomial $(n, p)$. Therefore</p>
$$
E(S_n \mid X = p) ~ = ~ np
$$<p>or, equivalently,</p>
$$
E(S_n \mid X) ~ = ~ nX
$$<p>By iteration,</p>
$$
E(S_n) ~ = ~ E(nX) ~ = ~ nE(X) ~ = ~ n\frac{r}{r+s}
$$<p>The expected proportion of heads in $n$ tosses is</p>
$$
E\big{(} \frac{S_n}{n} \big{)} ~ = ~ \frac{r}{r+s}
$$<p>which is the expectation of the prior distribution of $X$.</p>
<p>In the next section we will examine the long run behavior of this random proportion.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Endnote">Endnote<a class="anchor-link" href="#Endnote"> </a></h3><p>The unconditional probability $P(S_n = k)$ appeared in the denominator of our calculation of the posterior density of $X$ given $S_n$. Because of the simplifications that result from using conjugate priors, we were able to calculate the denominator in a couple of different ways. But often the calculation can be intractable, especially in high dimensional settings. Methods of dealing with this problem are covered in more advanced courses.</p>

</div>
</div>
</div>
</div>

 


    </main>
    